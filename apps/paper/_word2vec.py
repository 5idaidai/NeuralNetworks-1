#!/usr/bin/env python
# -*- coding: utf-8 -*-
'''
Created on March 6, 2014

@author: Chunwei Yan @ PKU
@mail:  yanchunwei@outlook.com

generate word vectors using word2vec from project gensim
'''
from __future__ import division
import os
import sys

from gensim.models.word2vec import Word2Vec

from dataset import DUC as DUCdataset

#import config

LEN_WORD_VECTOR = 100


def sentence_from_tree(tree):
    '''
    restore sentence from a parse tree
    to maintain consistence with word2vec's trainset
    '''
    words = []

    # preorder 
    def visit(node):
        if node:
            if node.is_leaf():
                word = node.get_word()
                words.append(word)
            else:
                visit(node.lchild)
                visit(node.rchild)
    visit(tree.root)
    return words


class Trainer(object):
    def __init__(self, sentences=[]):
        if sentences:
            self.word2vec = Word2Vec(sentences, size=LEN_WORD_VECTOR, window=5, min_count=0, workers=4)
        else:
            self.word2vec = Word2Vec()


    def get_word_vec(self, word):
        '''
        :parameters:
            word: string
        :return: array of float
            word vector generated by word2vec
        '''
        return self.word2vec[word]

    def model_tofile(self, filename):
        print 'save model to file:\t', filename
        self.word2vec.save(filename)

    def model_fromfile(self, filename):
        print 'load model from file:\t', filename
        self.word2vec = Word2Vec.load(filename)


def get_sentences_from_file(path):
    sentences = []
    with open(path) as f:
        while True:
            line = f.readline().strip()
            if not line: break
            ls = [s.lower() for s in line.split()]
            sentences.append(ls)
    print 'get %d sentences' % len(sentences)
    return sentences



if __name__ == "__main__":
    if len(sys.argv) == 1:
        print 'cmd topath paths'
        exit(-1)
    topath = sys.argv[1]
    paths = sys.stdin.read().split()
    sentences = []
    for path in paths:
        duc = DUCdataset(path)
        ss = duc.get_sentences()
        sentences += [duc.split_words(s) for s in ss]

    print 'generate sentences'
        
    trainer = Trainer(sentences)
    trainer.model_tofile(topath)
